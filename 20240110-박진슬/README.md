# 깃잔심 2+3 최종 발표

# 1. 프로젝트 요약

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled.png)

 

### 목적

- 글에 내포된 감정을 추출하고 그 감정을 통해 되돌아 볼 수 있는 서비스 생성
- 자연어 처리와 관련된 여러가지 태스크를 경험하고, 그 중 해당 서비스에 적용할 수 있는 부분을 적용

### 기능

- 글을 쓰고 싶어하는 사람들에게 글을 작성할 수 있는 공간을 제공
- 에세이 한편이 완료되면, 작성자의 감정을 분석하고 그 감정과 관련된 단어 통계를 제공

### 기대효과

- 사용자는 자기 자신의 단어 사용 행태를 파악할 수 있다
- 저자 별 단어-감정 사용 행태 비교를 통해 특징을 찾아낼 수 있다

# 2. 결과

[Project Moogeul - a Hugging Face Space by seriouspark](https://huggingface.co/spaces/seriouspark/project-moogeul)

## 서비스 구조

프로세스

| 내용 | 필요 데이터셋 | 필요 모델링 | 기타 필요항목 |
| --- | --- | --- | --- |
| 1. 단어 입력 시 에세이 1편을 쓸 수 있는 ‘글쓰기’ 공간 제공 | 네이버 한국어 사전 | - | streamlit 대시보드 |
| 2. 에세이 내 문장 분류 | 한국어 감정분석 자료 58000여건 | xlm-roberta | - |
| 3. 문장 별 감정 라벨 반환 | 한국어 감정분석 자료 58000여건 + 라벨 단순화 (60개 → 6개) | Bert Classifier |  |
| 4. 문장 내 명사, 형용사를 konlpy 활용하여 추출 | 한국어 감정분석 자료 58000여건 | konlpy Kkma | huggingface - pos tagger 검토 |
| 5. 명사, 형용사와 감정 라벨을 pair 로 만들어 빈도 집계 | - | - | - |
| 6. 해당 빈도 기반의 리뷰 제공 (저자 & 에세이리스트 수집) | yest24 칼럼 수집 
(은유, 정이현, 듀나, 총     건) | - | selenium / request / BeutifulSoup |

# 3. 서비스 사용 프로세스

## 1. 글쓰기

- 네이버 사전으로부터 받은 response 를 parsing
- 유저 **단어** 입력 → **사전 속 유사단어 리스트** 반환
- **사전 속 유사단어** 입력 → **사전 속 유사뜻 리스트** 반환

## 2.글 분석하기

- QA모델 활용해 **문장 → 감정 구**
- SentenceTransformer 활용해 **감정 구 → 임베딩**
- 분류모델 활용해 **(임베딩 - 라벨)** 학습
- roberta 활용해 **명사,형용사 추출**

# 4. 테스트 히스토리

### 1. QA모델

```jsx
model_name = 'AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru'
question = 'what is the person feeling?'
context = '슬퍼 아주 슬프고 힘들어'
question_answerer = pipeline(task = 'question-answering',model = model_name)
answer = question_answerer(question=question, context=context)

print(answer)
```

{'score': 0.5014625191688538, 'start': 0, 'end': 13, 'answer': '슬퍼 아주 슬프고 힘들어'}

- xlm-roberta-large-qa 모델구조
    - xlm : cross-lingual language model
        
        [참고자료](https://ariz1623.tistory.com/309)1 
        
        - 다국어를 목표로 사전학습 시킨 bert를 교차언어모델(xlm) dlfkrh qnfma
        - xlm 은 단일 언어 및 병렬 데이터셋을 사용해 사전학습
        - 병렬 데이터셋은 언어 쌍의 텍스트로 구성(동일한 내용의 2개 다른 언어 텍스트)
        - BPE를 사용하고 모든 언어에서 공유된 어휘를 사용
        - 사전 학습 전략
            - 인과언어모델링 CLM : 이전 단어셋에서 현재 단어의 확률을 예측
            - 마스크언어모델링 MLM : 토큰 15%를 무작위로 마스킹 후, 마스크된 토큰 예측 (80%은 [mask]로 교체, 10%는 임의 무작위 단어로 교체, 10%는 변경하지 않음
            - 번역 언어모델링 TLM : 서로 다른 언어로서 동일한 텍스트로 구성된 병렬 교차 언어모델을 이용
        - XLM-RoBERTa : 병렬 데이터셋을 구하기에 자료가 적은 언어를 학습하기 위해, MLM으로만 학습시키고 TLM은 사용하지 않음
    - qa 모델
        
        [참고자료](https://huggingface.co/tasks/question-answering) [노트북](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)
        
        - 학습 시 QG(question  generation) 과 QA(Question Answer) 부분으로 나뉨
    - config.json
        
        ```jsx
        {
          "_name_or_path": "AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru",
          "architectures": [
            "XLMRobertaForQuestionAnswering"
          ],
          "attention_probs_dropout_prob": 0.1,
          "bos_token_id": 0,
          "eos_token_id": 2,
          "gradient_checkpointing": false,
          "hidden_act": "gelu",
          "hidden_dropout_prob": 0.1,
          "hidden_size": 1024,
          "initializer_range": 0.02,
          "intermediate_size": 4096,
          "language": "english",
          "layer_norm_eps": 1e-05,
          "max_position_embeddings": 514,
          "model_type": "xlm-roberta",
          "name": "XLMRoberta",
          "num_attention_heads": 16,
          "num_hidden_layers": 24,
          "output_past": true,
          "pad_token_id": 1,
          "position_embedding_type": "absolute",
          "transformers_version": "4.6.1",
          "type_vocab_size": 1,
          "use_cache": true,
          "vocab_size": 250002
        }
        ```
        
    - RoBERTa
        - 트랜스포머 모델: RoBERTa는 BERT와 마찬가지로 트랜스포머 모델
        - 양방향 컨텍스트: RoBERTa는 문장의 양방향 컨텍스트를 고려
        - 대규모 데이터셋과 긴 트레이닝: RoBERTa는 BERT보다 더 많은 데이터와 더 긴 트레이닝 시간을 사용하여 모델을 훈련
        - BERT의 트레이닝 과정에 포함된 NSP 태스크를 RoBERTa는 제거
        
        ![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%201.png)
        
- 학습 데이터셋
    - Fine tuned on English and Russian QA datasets

```
model_name = 'monologg/koelectra-base-v2-finetuned-korquad'
question = 'what is the person feeling?'
context = '슬퍼 아주 슬프고 힘들어'
question_answerer = pipeline(task = 'question-answering',model = model_name)
answer = question_answerer(question=question, context=context)

print(answer)
```

{'score': 0.6014181971549988, 'start': 6, 'end': 13, 'answer': '슬프고 힘들어'}

- koelectra-base 모델구조
    
    ![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%202.png)
    
    [참고자료](https://tech.scatterlab.co.kr/electra-review/)1, [논문](https://arxiv.org/abs/2003.10555)
    
    - electra
        - 2020 구글 리서치 팀에서 발표한 모델
        - Efficiently Learning an Encoder that Classifies Token Replacements Accurately
        - BERT의 경우, 많은 양의 컴퓨팅 리소스를 필요로함
            - 하나의 문장에서 15%만 마스킹하기 때문에, 실제 학습하는 토큰이 15%
        - 입력을 마스킹 하는 대신, 소규모 네트워크에서 샘플링된 그럴듯한 대안으로 토큰을 대체함으로써 입력을 변경
        - 손상된 토큰의 원래 신원을 예측하는 모델을 훈련하는 대신, 손상된 입력의 각 토큰이 생성기 샘플로 대체되었는지 확인
            - original token VS replaced token 맞추는 것 간의 차이발생
    
    **⇒ Robert 와 비슷한 성능을 내면서 1/4 미만의 컴퓨팅 자원을 활용**
    
- 학습 데이터셋 : [참고링크](https://monologg.kr/2020/05/02/koelectra-part2/)
    - SKT의 KoBERT
    - TwoBlock AI의 HanBERT
    - ETRI의 KorBERT
    
    → 한자, 일부 특수문자 제거 / 한국어 문장 분리기 (kss) 사용 / 뉴스 관련 문장은 제거 (무단전재, (서울=뉴스1) 등 포함되면 무조건 제외)
    
- 최종 결과
    
    
    | index | score | start | end | answer |
    | --- | --- | --- | --- | --- |
    | 일은 왜 해도 해도 끝이 없을까? 화가 난다. | 0.9913754463195801 | 19 | 24 | 화가 난다 |
    | 이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나. | 0.5683395862579346 | 41 | 45 | 화가 나 |
    | 회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스트레스 받아. | 0.9996705651283264 | 45 | 49 | 스트레스 |
    | 직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 섭섭해. | 0.8939215540885925 | 42 | 49 | 분하고 섭섭해 |
    | 얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나. | 0.5234862565994263 | 32 | 34 | 화가 |
    | 직장에 다니고 있지만 시간만 버리는 거 같아. 진지하게 진로에 대한 고민이 생겨. | 0.9997361898422241 | 31 | 41 | 진로에 대한 고민이 |
    | 성인인데도 진로를 아직도 못 정했다고 부모님이 노여워하셔. 나도 섭섭해. | 0.9988294839859009 | 36 | 39 | 섭섭해 |
    | 퇴사한 지 얼마 안 됐지만 천천히 직장을 구해보려고. | 0.5484525561332703 | 19 | 28 | 직장을 구해보려고 |
    | 졸업반이라서 취업을 생각해야 하는데 지금 너무 느긋해서 이래도 되나 싶어. | 0.9842100739479065 | 7 | 15 | 취업을 생각해야 |
    | 요즘 직장생활이 너무 편하고 좋은 것 같아! | 0.1027943417429924 | 3 | 8 | 직장생활이 |
    | 취업해야 할 나이인데 취업하고 싶지가 않아. | 0.10440643876791 | 7 | 11 | 나이인데 |
    | 면접에서 부모님 직업에 대한 질문이 들어왔어. | 0.9965717792510986 | 5 | 12 | 부모님 직업에 |
    | 큰일이야. 부장님께 결재받아야 하는 서류가 사라졌어. 한 시간 뒤에 제출해야 하는데 어디로 갔지? | 0.07094824314117432 | 0 | 5 | 큰일이야. |
    | 나 얼마 전에 면접 본 회사에서 면접 합격했다고 연락받았었는데 오늘 다시 입사 취소 통보받아서 당혹스러워. | 0.998587429523468 | 53 | 58 | 당혹스러워 |
    | 길을 가다가 우연히 마주친 동네 아주머니께서 취업했냐고 물어보셔서 당황했어. | 0.9999895095825195 | 37 | 41 | 당황했어 |
    | 어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽고 속상해. | 0.8316713571548462 | 42 | 51 | 당혹스럽고 속상해 |
    | 나 오늘 첫 출근 했는데 너무 당황스러웠어! | 0.9923190474510193 | 17 | 23 | 당황스러웠어 |
    | 이번에 직장을 이직했는데 글쎄 만나고 싶지 않은 사람을 만나서 아주 당황스럽더라고. | 0.4635336995124817 | 38 | 45 | 당황스럽더라고 |

## 2. 임베딩 모델

```jsx
tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
tokenizer .encode('당혹스럽고 속상해')
```

- 임베딩 값 (, 10)
    
    (`[101, 9067, 119438, 12605, 118867, 11664, 9449, 14871, 14523, 102]`)
    
- tokenizer

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%203.png)

[참고자료](https://riverkangg.github.io/nlp/nlp-bertWordEmbedding/)

```jsx
from sentence_transformers import SentenceTransformer

encoder = SentenceTransformer('jhgan/ko-sroberta-multitask')
sentences = ['당혹스럽고 속상해',]
embeddings = encoder.encode(sentences)
print(embeddings)
```

- 임베딩 값 (1, 768)
    
    [[-0.8137736  -0.37767226  0.00479629 -0.7122745  -0.6188193  -0.8070712
    0.33743355  0.07861519  0.3211138  -0.37560478 -0.5427672   0.11924683
    0.0986286   0.40359694 -0.46937665  0.02394157  0.285122    0.55982906
    0.38515273 -0.3988298  -0.19845179  0.13936345  0.14499584  0.24853697
    0.30090114  0.40483928  0.04216868  0.5139026  -0.46236628  0.4332235
    0.5616551  -0.10100467 -0.02607241  0.6462534   0.40517992  0.15661277
    -0.2467836  -0.04643329  0.24358888 -0.29130867 -0.46411756  0.357318
    0.7531052   0.50181943 -1.0836693  -0.22909476 -0.192317   -0.4927135
    -0.25188023  0.1042927   0.01742885 -0.706377    0.7105427   0.31926626
    0.5455656  -0.10863421 -0.7115043  -0.16358532  0.64703697 -0.19304956
    0.78443927 -0.10025603  0.5193046   0.23209657  0.06545047  0.15368763
    -0.2928548   0.5775732  -0.5461035   0.17605427  0.22253372  0.9803986
    -0.4301873  -0.66158235  0.1779921   0.22802618 -0.66418976  0.04856539
    0.569779    0.38404003 -0.4758539   0.31692514 -0.2997773  -0.6626848
    0.2354552   0.7253365   0.3412356  -0.34355187 -0.8480019  -0.0544516
    -0.37409583 -0.86678344 -0.25223726 -0.17733721  0.25018314 -0.06625105
    0.04267805  0.37135214  0.5929218   0.4031136   0.16019678 -0.44704866
    -0.5545972   0.24475893  0.6347926   0.07221922 -0.06400843  0.5754295
    -0.45951408 -0.1212417   0.32270595 -0.13821569 -0.6383653  -0.11860011
    0.35245472  0.29802546 -0.6586127  -0.03610338 -0.6296664   0.17055835
    -0.2571332  -0.38481686  0.11305644  0.20419933 -0.82833236 -0.07909187
    -0.69967973  0.00203036  0.1020183  -0.1305389   0.26934174 -0.12709348
    0.5007263   0.04159525  0.0540274  -0.2391515  -0.30841854  0.1999257
    0.34817147 -0.03168721  0.16783062 -0.29950666  0.05632884 -0.4544269
    -0.20042829 -0.20340374 -0.03199184  0.43718454 -0.1412448  -0.17962322
    -0.5484413   0.553651   -0.17305787  0.7085422   0.364388   -1.2738247
    -0.23946735  0.17515986  0.36452243  0.11487053 -0.5900279  -0.21997337
    -0.14607096  0.13973871  0.11223572 -0.24279508  0.02733397  0.13989227
    -0.03282901 -0.40634915 -0.4401279   0.07281438  0.23345292  0.27184114
    -0.4208961   0.12617172  0.39679822  0.13727804 -0.29430562 -0.34261212
    0.40343532  0.38669655  0.5053225  -0.31863266  0.21391715  0.7117067
    -0.01480521 -0.0558925   0.01653404 -0.1817904   0.23767576  0.24156694
    0.29653308  0.12403929  0.2866649   0.06660177 -0.3597462  -0.12619112
    -0.09134455  0.15372913 -0.69411355 -0.678101   -0.16476674  0.3718488
    0.00803786  0.10039866  0.07667284  0.3123631   0.8419223   0.15198457
    -0.2705328  -0.00911014  0.09063043  0.3506619   0.0954851  -0.01424682
    0.04509389 -0.3740499  -0.4248653  -0.03004187 -0.11564978 -0.5107252
    0.6690965  -0.84854454  0.07027241  0.13535842  0.25501665  0.10351561
    -0.02793748 -0.00566786  0.45210546 -0.48621964  0.10718656 -1.2502406
    -0.00354779  0.00587439  0.12320428  0.10517848 -0.35567597 -0.10687869
    -0.7759796  -0.09507401  0.07931711 -0.29233798 -0.14195187 -0.05996962
    -1.0224656  -0.777847   -0.09761698 -0.3044826  -0.08161807  0.32240957
    -0.09577129  0.36681274 -0.53162354 -0.41301352 -0.19215153  0.18189147
    -0.0710187   0.1794347   0.49542806 -0.09026273  0.08548423  0.23502824
    0.34774557 -0.39110926 -0.24370289  0.11981336 -0.04926207 -0.36029306
    0.15732484 -0.3201125  -0.05043215 -0.39981684  0.700211    0.5844002
    -0.6422023   0.18528195 -0.2685204  -0.37325934  0.5601      0.17824127
    0.44196954 -0.05767169 -0.36278683 -0.50682515  0.69593334 -0.6036307
    -0.26322168 -0.3285593  -0.07512035  0.15891753 -0.33953363 -1.4154313
    -0.48975343 -0.1954787   0.15840803 -0.05310624  0.50545937  0.12895793
    0.0342275   0.9483997   0.01944764  0.3771155  -0.02041904  0.20641443
    -0.53563946 -0.70512474  0.03738637 -0.41387576  0.24414015 -0.4433017
    -0.5890064   0.07696963  0.16543111 -0.48978335  0.52443    -0.26288977
    -0.50333315  0.12278434  0.34489706  0.04064272  0.01425712 -0.5701094
    -0.2809623  -0.24639694  0.14783995 -0.2396182   0.24541482  0.386652
    -0.19201453 -0.53591627 -0.11871038 -0.15532787  0.07801197 -0.2130351
    0.12973396  0.35090557  0.2947023  -0.16787732  0.61988336  0.17927861
    -0.12317734 -0.08802772  0.45541432  1.9041836   0.61920345  0.07730291
    0.1516366  -0.3903234   0.05004438  0.41030237 -0.3327791  -0.59869164
    0.3797493   0.8188715  -0.18980739 -0.10242856  0.74707043  0.04325995
    0.38830444  0.44989067  0.5846638  -0.49637276 -0.20508404  0.12211239
    -0.3322715   0.9338848   0.33361623  0.17625114  0.04394255  0.17465411
    0.4460369  -0.4309755   0.26075467 -0.48126408 -0.60347474  0.11257023
    0.3578127  -0.5533394   0.09454099  0.09270767  0.28545937 -0.794048
    -0.15476522 -0.06691877 -0.0923596  -0.38963673  0.03135515 -0.38017634
    0.28381085  0.6768397  -0.50233835 -0.10008664 -0.3181272  -0.00854804
    -0.12051769 -0.4328291  -0.11608122 -0.24905048  0.4231929   0.46701187
    -0.5243311   0.6802627  -0.2323803  -0.52542967  0.24336325 -0.6450524
    -0.4702766  -0.24581897  0.07273103 -0.34896797  0.06221877 -1.4226849
    0.25136423 -0.23438893  0.02641286  0.07846476  0.04952943  0.68315524
    0.2331879   0.2223695   0.15711959 -0.2677463   0.18712093  0.09920471
    0.00936144  0.08287239 -0.6621276   0.13395558  0.34844652 -0.6672276
    -0.36684904 -0.58201206  0.37181792 -0.04191176  0.1967919  -0.28824928
    0.24891064 -0.23210165 -0.28040385 -0.7093344  -0.8406623  -0.4629052
    -0.0776682  -0.10932059  0.07862072  0.37556538 -0.710132    0.07044489
    -0.09219015  0.45410427  0.11107908 -0.10632848 -0.38065654  0.09514569
    0.00730813 -0.08670639  0.43460587 -0.49437493  0.06000489 -0.7353855
    -0.16049947 -0.44631082 -0.10140591 -0.26270083 -0.04901508  0.49348888
    0.35803813 -0.16186948 -0.09306639 -0.09256689 -0.08160831  0.5192736
    0.22966255  0.27684313  0.1913234   0.2620284  -0.05626464  0.2667561
    0.02493648 -0.31351215  0.22637773  0.06618267  0.1875025   0.07317775
    0.15057611 -0.21586217 -0.00383155  0.84085304 -1.2704498   0.15301347
    -0.4613875  -0.09395627  0.22832072 -0.45235252 -0.00283988 -0.02684523
    -0.677063   -0.1196053  -0.27901858  0.00970934  0.30084032 -0.5269693
    0.6912351   0.47386426 -0.87440586 -0.4573329   0.1308219  -0.33114794
    -0.14963937 -0.02414569  0.5585877  -0.33563805  0.6646422   0.22186914
    -0.30241743  0.35896352 -0.10412224 -0.49735385 -0.84037334 -0.12174014
    -0.11365729 -0.32239458  0.04202841  0.36043006  0.4165175  -0.23518896
    -0.27234918 -0.34339896 -0.11750535  0.44654784  0.30322137  0.49742058
    0.47342604  0.8625161   0.21463563  0.57339823 -0.09199458  0.43663636
    0.10610653 -0.1187556  -0.3071391   0.21523437 -0.19135514  0.21764119
    0.69426817  0.11649054 -1.0484879  -0.28955147  0.07587141  0.1096257
    -0.623282   -1.0626923  -0.39674282 -0.84520406 -0.5769718  -0.56509066
    0.54058737 -0.4691785  -0.4756179   0.08784817 -0.6064978   0.251713
    0.4296349  -0.41222197  0.48138827  0.1700339   0.08672174  0.10949554
    0.7634717  -0.4488383  -0.03344278 -0.21894993  0.26941606 -0.20194091
    -0.44669658 -1.0421406  -0.72041243 -0.22172807 -0.1761415  -0.35117564
    -0.1962428   0.86577874 -0.149622   -0.3057272  -0.26702234  0.45503047
    -0.7001557   0.16868176  0.05929234 -0.13893948  1.228433   -0.31952605
    -0.8585965  -0.6235496  -0.01840534  0.35861677  0.6253322  -0.4833035
    0.3805162   0.1784979  -0.6914177  -0.6396288  -0.531805   -0.3970099
    0.7949857  -0.34655645 -0.49330202  0.07707165  0.11607818 -1.29539
    -0.8127719   0.68748945  0.09936623  0.31852198  0.04080894 -0.4341039
    0.4242194   0.07937627 -0.45251748  0.3399384  -0.5033408   0.40207317
    -0.23878309  0.35989836  0.74258786 -0.16690072  0.12447127  0.13650596
    0.6865877  -0.15736553  0.09115729  0.3423802  -0.57945204 -0.01446251
    -0.1335552  -0.00442058 -0.5285459  -0.2710252   0.36510077 -0.7966
    -0.4341987   0.45466867  0.15511288  0.21757865 -0.08237614 -0.6084242
    -0.7186505   0.70279855 -0.46631292  0.03936601  0.60398066 -0.03022094
    0.50824815  0.2012453  -0.19866772  0.05400682  0.10675537  0.08649515
    0.17659184  0.23076975  0.22351906 -0.11995713 -0.02689737  0.0471752
    -0.22110806  1.0326171   0.8444457  -0.23468916  0.2449751  -0.5197468
    0.23262593 -0.31978798 -0.87465006 -0.20095049  0.35623202 -0.22360447
    -0.9557438  -0.8665797  -0.04599928 -0.8627014  -0.43375593  0.0080547
    0.40917936  0.21636854  0.5061203  -0.11724357  0.38334846  0.10356375
    0.4217896   0.03005661 -0.8827422  -0.5075221   0.41059628  0.28699416
    -0.08436231  0.24593388  0.13365766 -0.08906917 -0.24679865  0.16487692
    -0.43479028 -0.00786455 -0.49440986  0.32472187  0.20649779 -0.24681807
    -0.4073419  -0.20102029 -0.32104495  0.10125852 -0.05705288 -0.2633032
    -0.22951654 -0.3875762  -0.5041043   0.24398923  0.312636   -0.37885946
    0.23600677 -0.04873028 -0.25942662  0.12602977  0.11458492  0.4059717
    0.11098696  0.43832663 -0.00348338 -0.6075282   0.1710683  -0.7117046
    0.58617175 -0.30523697  0.39697883 -0.03496478  0.5791693   0.06771571
    -0.01527995  0.33567953 -0.11176416  0.44348866 -0.4243882   0.56027734
    -0.92194456  0.69189864 -0.8041991  -0.34339267 -0.00724071  0.111375
    -0.25833672  0.32122892  0.18401429  0.04765312 -0.1398647  -0.42618805
    0.15546215  0.31039104  0.07697397 -0.1855451  -0.15515445  0.31056032
    -0.02835898  0.3789186   0.3673397   0.562495   -0.4278595  -0.4228025 ]]
    
- SentenceTransformer [참고자료](https://www.sbert.net/docs/publications.html)
    
    ![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%204.png)
    

```jsx
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: RobertaModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
)
```

## 3. 분류모델

- 평가기준 accuracy (from sklearn.metrics import accuracy_score)
- baseline : 0.17 (label 6개 중 1개 임의 선택될 비율,  1/6)

```python
#1차
class BertClassifier(nn.Module):

  def __init__(self, dropout = 0.3):
    super(BertClassifier, self).__init__()

    self.bert= BertModel.from_pretrained('bert-base-multilingual-cased')
    self.dropout = nn.Dropout(dropout)
    self.linear = nn.Linear(768, 6)
    self.relu = nn.ReLU()

  def forward(self, input_id, mask):
    _, pooled_output = self.bert(input_ids = input_id, attention_mask = mask, return_dict = False)
    dropout_output = self.dropout(pooled_output)
    linear_output = self.linear(dropout_output)
    final_layer= self.relu(linear_output)

    return final_layer

# 2차
model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased',  )
```

**accuracy 55.7%**

- bert 모델
    - 다중 언어 모델에 dropout / linear / relu 를 추가한 함수
    - epoch = 2 : 적정 수준 (train / test accuracy 0.55~0.57)
    - epoch = 10 : 과적합 (train accuracy 0.98 / test accuracy = 0.56)
        
        → epoch = 2 에서 학습한 수준과 epoch 10에서 학습한 데이터 패턴이 크게 다르지 않음
        

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%205.png)

```jsx
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)

model = RandomForestClassifier()
model.fit(X_train_features_top50, X_train_label)
prediction = model.predict(X_test_features_top50)
score = accuracy_score(X_test_label, prediction)
print('top50 accuracy: ', score) # 더떨어졌다.

models = [
    RandomForestClassifier(),
    LogisticRegression(max_iter = 5000),
    SVC()
]

grid_searches = []
for model in models:
  grid_search = GridSearchCV(model, param_grid = {}, cv = 5)
  grid_searches.append(grid_search)

for grid_search in tqdm(grid_searches):
  grid_search.fit(X_train_feature, X_train_label)

best_models = []
for grid_search in grid_searches:
  best_model = grid_search.best_estimator_
  best_model.append(best_model)

ensemble_model = VotingClassifier(best_models)
ensemble_model.fit(X_train_feature, X_train_label)
predictions = ensemble_model.predict(X_test_feature)
accuracy = accuracy_score(X_test_label, predictions)
```

**accuracy 60.3%**

- [RandomForestClassifier](https://medium.com/analytics-vidhya/random-forest-classifier-and-its-hyperparameters-8467bec755f6)

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%206.png)

- [LogisticRegression](https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac)

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%207.png)

- [SVC](https://scikit-learn.org/stable/modules/svm.html)

![Untitled](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/Untitled%208.png)

## 4. 명사/형용사 추출

```python
from konlpy.tag import Okt

okt = Okt()

def get_noun(text):
  noun_list = [k for k, v  in okt.pos(text) if (v == 'Noun' and len(k) > 1)]
  return noun_list
def get_adj(text):
  adj_list = [k for k, v  in okt.pos(text) if (v == 'Adjective') and (len(k) > 1)]
  return adj_list
def get_verb(text):
  verb_list = [k for k, v  in okt.pos(text) if (v == 'Verb') and (len(k) > 1)]
  return verb_list

text = '어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽고 속상해.'

get_noun(text)
get_adj(text)
get_verb(text)
```

get_noun: `['어제', '합격', '통보', '회사', '문자', '잘못', '발송', '연락']`

get_adj: `['당혹스럽고', '속상해']`

get_verb: `['받은', '했다고', '왔어']`

- [OKt](https://konlpy.org/en/latest/api/konlpy.tag/#okt-class)

```python
tokenizer=AutoTokenizer.from_pretrained("KoichiYasuoka/roberta-large-korean-upos")
posmodel=AutoModelForTokenClassification.from_pretrained("KoichiYasuoka/roberta-large-korean-upos")

pipeline=TokenClassificationPipeline(tokenizer=tokenizer,
                                     model=posmodel,
                                     aggregation_strategy="simple",
                                     task = 'token-classification')
nlp=lambda x:[(x[t["start"]:t["end"]],t["entity_group"]) for t in pipeline(x)]
nlp(text)

# result
[('어제 합격', 'NOUN'),
 ('통보를', 'NOUN'),
 ('받은', 'VERB'),
 ('회사에서', 'ADV'),
 ('문자를', 'NOUN'),
 ('잘못', 'ADV'),
 ('발송했다고', 'VERB'),
 ('연락이', 'NOUN'),
 ('왔어', 'VERB'),
 ('.', 'PUNCT'),
 ('너무', 'ADV'),
 ('당혹스럽고', 'CCONJ'),
 ('속상해', 'VERB'),
 ('.', 'PUNCT')]
```

- [roberta-large](https://github.com/KLUE-benchmark/KLUE) → KLUE → 한문 교육용 기초 한자 & 인명용 한자를 추가
- RoBERTa(Robustly optimized BERT approach)
    - 
    - [https://huggingface.co/klue/roberta-large](https://huggingface.co/klue/roberta-large)
        
        [https://huggingface.co/KoichiYasuoka/roberta-large-korean-hanja](https://huggingface.co/KoichiYasuoka/roberta-large-korean-hanja)
        
- [데이터셋](https://huggingface.co/KoichiYasuoka/roberta-large-korean-upos/raw/main/vocab.txt)

```jsx
from konlpy.tag import Okt

okt = Okt()

def get_noun(text):
  noun_list = [k for k, v  in okt.pos(text) if (v == 'Noun' and len(k) > 1)]
  return noun_list
def get_adj(text):
  adj_list = [k for k, v  in okt.pos(text) if (v == 'Adjective') and (len(k) > 1)]
  return adj_list
def get_verb(text):
  verb_list = [k for k, v  in okt.pos(text) if (v == 'Verb') and (len(k) > 1)]
  return verb_list

text = '어제 합격 통보를 받은 회사에서 문자를 잘못 발송했다고 연락이 왔어. 너무 당혹스럽고 속상해.'

get_noun(text)
get_adj(text)
get_verb(text)
```

get_noun: `['어제', '합격', '통보', '회사', '문자', '잘못', '발송', '연락']`

get_adj: `['당혹스럽고', '속상해']`

get_verb: `['받은', '했다고', '왔어']`

- [OKt](https://konlpy.org/en/latest/api/konlpy.tag/#okt-class)

# 4. **분석 리포트**

### 1. 저자 분석 가이드라인

- 총 발행 글 수
    - 글 당 문장 수
        1. 글 속 문장 갯수
        2. 글 속 단어 갯수
            
            명사 수 / 형용사 수
            
        3. 문장 기준 최고 감정
        4. 단어 기준 최고 감정
        5. 단어 별 감정 갯수
    - 글 별 감정 / 단어 (명사, 형용사)
        - 감정 1건당 단어 유니크 수 : 가장 다채로운 단어를 사용한 감정은 ?
        - 감정 1건 당 최다 단어 : 그 감정을 대표하는 단어는? / 어떤 단어를 쓸 때 그 감정이 많이 올라왔을까?
        - 단어 1건당 유니크 감정 : 가장 복잡한 감정을 만들어낸 단어는?
        - 단어 1건당 최다 감정 : 그 단어를 쓸 때 어떤 감정이 많이 올라왔을까?

### 2. **예시**

- 에세이스트 <은유> / 총 17개의 에세이 수집
    
    ```python
    # 제목 : 사랑에 빠지지 않는 한 사랑은 없다
    
    영화 <나의 사랑, 그리스>의 한 장면
    
    한 사람에게 다가오는 사랑의 기회에 관심이 많다. 이제껏 사랑을 몇 번 해봤느냐는 물음을 실없이 던져보기도 한다.
     상대는 거의 머뭇거린다. 사랑과 사랑 아닌 것의 기준 설정부터 간단치 않은 거다.
    내게 사랑은 나 아닌 것에 ‘빠져듦’ 그리고 ‘달라짐’이다.
    우연한 계기로 엮여  서로의 세계를 흡수하면서 안 하던 짓을 하거나 하던 짓을 안 하게 되는 일.
    연애가 그랬고 공부가 그랬다. 이전과 다른 삶으로 넘어가는 계기적 사건이 사랑 같다.
    영화 〈나의 사랑, 그리스〉에는 내 어설픈 사랑 연구에 맞춤한 세 편의 이야기가 나온다.
    각기 다른 세대의 이성애 커플이 등장하는 옴니버스식 구성인데 스토리가 촘촘하고 풍성하다.
    “우린 모두 각기 다른 얼굴이지만 사랑에 빠졌을 때만은 같은 얼굴이다”라는 극중 대사처럼,
    그리스의 경제, 외교, 정치 조건에서 그들이 겪는 곤란은 다르지만 나이와 국적을 불문하고 사랑하는 모습은 닮은꼴이다.
    청년 커플은 그리스 여대생과 시리아 이민자 남성이다. 경제 위기에 처한 그리스인들에겐 기근과 전쟁을 피해 흘러든 이방인은 불청객이다.
    정치학을 전공하는 여대생은 수업시간 교수가 말하는 난민 문제에 집중하지 못한다.
    그녀에게 난민은 토론 과제가 아니라 만져지는 ‘사람’이기 때문이다.
    이민자 남자는 그리스인들 사이에 있을 땐 사회에 불안과 공포를 조성하는 혐오의 대상이지만
    그녀와 있을 땐 시리아에서 태어난 순박하고 정의로운 예술가 청년이 된다. 인
    종이나 계급, 문화의 차이는 차별의 근거가 아니라 사랑의 동력으로 작용한다.
    그들은 닥칠지도 모르는 불안에 미리 쪼그라들거나 위험을 계산해 행동하지 않는다.
    늘 불안한 눈빛을 보였던 그는 같은 사람인가 싶을 정도로 변한다.
    그녀 곁에선 천진한 웃음의 존재로 개화한다.
    중년 커플은 파산 위기를 맞는 그리스 회사 직원과 그 회사의 구조조정 책임자로 온 스웨덴 여성의 사랑을 그린다.
    하루하루 실적으로 평가 받는 마케팅 업무의 스트레스와 쇼윈도 부부 노릇에 지친 중년 남자는 공황장애 약을 먹으며 간신히 일상을 지탱한다.
    왜 그런 약을 먹느냐며 남자의 나약함을 비웃는 그녀. 사랑에 빠지면서 숫자만 보이다가
     ‘사람’이 보이기 시작하자 그녀의 냉정하고 빈틈없는 사고 체계에는 교란이 일어난다.
    자본주의의 생리인 신속함과 무자비함을 요구하는 본사의 닦달을 못 이기고 업무를 포기한다.
    그리고 그가 먹던 알약 로세프트 50mg을 삼킨다. 이제 그녀는 남의 밥줄 끊는 일은 하지 못하는 사람이 된다.
    노년 커플은 그리스인 평범한 주부와 독일에서 이주해온 역사학자 남자다. 사랑이 잉태되는 공간은 마트.
    그녀는 절박하다. 장바구니에 토마토 한 상자를 넣었다 뺐다 할 정도로 생활고가 극심하다. 아직도 싱크대 앞에서 ‘이게 내가 원하던 삶인가’ 한숨 쉰다.
    이런저런 고민을 그에게 터놓는다. 서툰 영어로 더듬더듬. 마트 밖은 위험하다고 여기는 그녀를 남자는 신화의 세계로 인도한다.
    그녀는 그가 선물한 두툼한 신화 원서를 읽고자 돋보기를 쓰고 영어사전을 편다.
    혼자 힘으론 불가능한 말하기, 듣기, 읽기의 세계를 그의 꾸준한 도움으로 통과한 그녀는
    자신이 목도한 부조리에 항의하는 사람, 눈치 보지 않고 자기 생각을 당당히 표현하는 사람이 된다.
    이것이 사랑의 급진성이 아닌가. 나는 영화를 보는 내내 ‘사랑에 빠지기 그것은 곧 혁명’이라고 말하는 책 『사랑의 급진성』을 떠올렸다.
    한 사람의 이민자가 혐오의 대상에서 환대의 대상이 되고, 해고하는 사람이 해고하지 못하는 사람이 되고, 공부하지 않던 사람이 공부하는 사람이 된다.
    “범상한 일상, 새로운 것은 무엇이든 생겨날 수 없게끔 사방에 켜켜이 쌓인 먼지의 단층에 하나의 균열이 생기는 사건”(12쪽)이라는 혁명의 정의대로,
    영화 속 주인공들은 사랑이라는 ‘일인분의 혁명’을 완수한다. 한 사람이 바뀌면 세상도 약간 방향을 튼다는 점에서 그것은 역사적 사건이기도 하다.
    이 영화에는 또 다른 주인공, 사랑에 무능력한 존재가 나온다. 극우 파시스트 조직에 가담해 유럽 난민에게 무차별한 테러를 자행하는 인물이다.
    그는 시대의 불운으로 인한 자기 삶의 실패와 불만족을 이민자 같은 사회적 약자에게 투사하며 혐오의 일그러진 얼굴로 살아간다.
    혐오를 뿌리고 혐오를 거두는 악순환의 고리에 갇힌다. 누구나 하루하루 열심히 사는 일상은 비슷할지 모르나 사랑의 있고 없음으로
    훗날 다른 얼굴 다른 관계가 만들어진다는 것을 그는 삶으로 보여준다. 그렇다면 어떻게 사랑의 주체로 살아갈 수 있을까.
    무엇이 사랑이고 무엇이 사랑 아닌가 하는 물음에 『사랑의 급진성』 저자는 이렇게 말한다. “위험 제로의 사랑은 사랑이 아니다. ”(19쪽)
    성적 욕망으로 팽배한 현대사회지만 아이러니하게 사랑에 빠지는 것을 두려워한다며 자기동일성에 안주하는 현대인의 왜소함을 저자는 지적한다.
    “결과가 어떻든 간에 위험을 무릅쓰는 것, 이 숙명적인 만남으로 인해 일상의 좌표가 변경되리라는 점을 알면서도, 오히려 바로 그런 이유에서 만남을 갈구하는 것”(166쪽)이 사랑이다.
    사랑에 빠지는 원인은 세 가지다. “첫째는 보는 것, 둘째는 듣는 것, 셋째는 연인의 후한 마음”(19쪽) 영화 〈나의 사랑, 그리스〉의 세 커플도 각각 낯선 사람에게 눈길을 건네는 사소한 행위로부터 사랑이 시작된다.
    거기에 사람이 있다는 것을 보고, 그 사람의 이야기를 듣고, 시간과 정성을 후하게 쏟으며 사랑의 주체가 된다.
    "사랑에 빠지지 않는 한 사랑은 없다. "(151쪽) 사랑은 특별한 지식이나 기술이 필요치 않다는 점에서 쉽고, 자기를 내려놓아야 한다는 점에서 어렵다.
    그러니 사랑을 얼마나 해보았느냐는 질문은 이렇게 바꿀 수도 있다. 당신은 다른 존재가 되어보았느냐. 왜 사랑이 필요하냐고 묻는다면,
    비활성화된 자아의 활성화가 암울한 현실에 숨구멍을 열어주기 때문이라고 답하겠다. 존재의 등이 켜지는 순간 사랑은 속삭인다. “삶을 붙들고 최선을 다해요. ”(123쪽)
    
    ```
    
- 총 발행 글 수 : 17건
- 70.35 문장 / 1글
- 글 속 문장 개수

| title | 문장 수 |
| --- | --- |
| '불쌍한 아이' 만드는 '이상한 어른들' | 53 |
| 글쓰기는 나와 친해지는 일 | 62 |
| 나를 아프게 하는 착한 사람들 | 65 |
| 다정한 얼굴을 완성하는 법 | 65 |
| 딸에 대하여, 실은 엄마에 대하여 | 68 |
| 마침내 사는 법을 배우다 | 64 |
| 만국의 싱글 레이디스여, 버텨주오\! | 69 |
| 문명의 편리가 누군가의 죽음에 빚지고 있음을 | 87 |
| 사랑에 빠지지 않는 한 사랑은 없다 | 63 |
| 성폭력 가해자에게 편지를 보냈다 | 83 |
| 슬픔을 공부해야 하는 이유 | 70 |
| 알려주지 않으면 그 이유를 모르시겠어요? | 67 |
| 우리는 왜 살수록 빚쟁이가 되는가 | 73 |
| 울더라도 정확하게 말하는 것 | 77 |
| 인공자궁을 생각함 | 79 |
| 친구 같은 엄마와 딸이라는 환상 | 80 |
| 하찮은 만남들에 대한 예의 | 88 |
- 글 속 단어 개수

![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.38.52.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.38.52.png)

- 문장 기준 최고 감정
    - 에세이를 구성하는 문장의 감정 라벨을 집계
    - ‘**글쓰기는 나와 친해지는일’** 이라는 에세이에서는 [불안] 이 가장 높으며 [기쁨] 과 [분노] 가 그 다음 감
    
    → 문장 분류 모델의 정확도 상승시, 해당 방식으로 에세이 별 ‘주요 감정’ 을 쉽게 구분 및 비교할 수 있음
    
    ![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.40.49.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.40.49.png)
    
- **단어 기준 최고 감정 / 단어 별 감정 개수**
    - 명사와 형용사를 합쳤을 경우, 아니라/없는 등의 단어들이 상위에 위치
    - 명사만 추출 시, 2개 이상의 감정이 담긴 단어는 찾지 못함
    
    → 더 많은 에세이를 수집 / lemmatized 된 단어를 사용해 의미 기준으로 재구성이 가능해보임
    

[명사 + 형용사]

![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.41.23.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.41.23.png)

[명사]

![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.41.36.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_17.41.36.png)

- 가장 다채로운 단어를 사용한 감정은 ? (감정 별 문장 1건당 단어)
    - [불안] 단어 종류가 954건으로 가장 많음
    - 문장 수로 나눠보았을 때, [당황] 의 감정이 3.24건으로 문장 1건에서 3개 이상의 단어들이 추출되어 매핑
    
    | emotion | vocab_cnt | sentence_cnt | vocab_per_sentence |
    | --- | --- | --- | --- |
    | 불안 | 954 | 327 | 2.917431 |
    | 슬픔 | 681 | 245 | 2.779592 |
    | 분노 | 736 | 260 | 2.917431 |
    | 기쁨 | 541 | 197 | 2.746193 |
    | 당황 | 318 | 98 | 3.244898 |
    | 상처 | 272 | 86 | 3.162791 |
- 그 감정을 대표하는 단어는? / 어떤 단어를 쓸 때 그 감정이 많이 올라왔을까? (감정 1건 당 최다 단어)
    - [당황] 의 경우 부끄러운, 이상한 이라는 단어가 상위에 존재
    - 그 외의 감정의 경우, 단어로 특성을 찾기 어려움
    
    → 빈도가 높은 단어들이 상위에 존재하여, 해당 방식으로 추출 뒤 tfidf 등의 빈도 기반 스코어로 단어 추가 정렬이 가능해보임
    
    ![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.21.16.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.21.16.png)
    
- 가장 복잡한 감정을 만들어낸 단어는? (단어 1건당 유니크 감정)
    - 있는, 없는, 있는, 있다 등이 가장 많이 등장하였고, 그에 따른 감정종류도 가장 많음
    - 단어 맥락에 따라 어느 부분에나 쉽게 적용될 수 있기 때문에 해당 값들이 모든 감정을 가지고 있음
    
    → 복잡한 감정의 기준을 다시 제시하고 (예: 상충되는 감정 ) 그에 따른 ‘복잡한 감정' 과 ‘단어’ 조합을 찾아볼 수 있음
    
    ![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.21.23.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.21.23.png)
    
    ![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.22.43.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.22.43.png)
    
- 그 단어를 쓸 때 어떤 감정이 많이 올라왔을까? (단어 1건당 최다 감정)
    - [좋아하는] 단어의 경우, 불안 :2 , 기쁨 : 1 , 상처 : 1
    - [부끄러운] 단어의 경우, 당황 : 4
    - [나약한] 단어의 경우 기쁨 : 1
    
    ![%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.30.48.png](%E1%84%80%E1%85%B5%E1%86%BA%E1%84%8C%E1%85%A1%E1%86%AB%E1%84%89%E1%85%B5%E1%86%B7%202+3%20%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%87%E1%85%A1%E1%86%AF%E1%84%91%E1%85%AD%20f752e38993954a73adb6de055145b1ce/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-10-25_18.30.48.png)